{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY_ID\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca Key type: <class 'str'>\n",
      "Alpaca Secret Key type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Verify that Alpaca key and secret were correctly loaded\n",
    "print(f\"Alpaca Key type: {type(alpaca_api_key)}\")\n",
    "print(f\"Alpaca Secret Key type: {type(alpaca_secret_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Alpaca API object\n",
    "api = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version = \"v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timeframe to '1D' pulling non-vol stock data\n",
    "timeframe = \"1D\"\n",
    "\n",
    "# Set start and end datetimes between now and 3 years ago.\n",
    "start_date = pd.Timestamp(\"2019-01-01\", tz=\"America/New_York\").isoformat()\n",
    "end_date = pd.Timestamp(\"2021-06-01\", tz=\"America/New_York\").isoformat()\n",
    "# Set the ticker informationkrak\n",
    "tickers = [\"WKHS\",\"OPTI\",\"LTRPB\",]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\"Small cap\":[\"WKHS\",\"OPTI\",\"LTRPB\"], \"Mid cap\":[\"RIOT\",\"TTD\",\"DXC\"],\"Large cap\":[\"SQ\",\"IBM\",\"ENPH\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df_ibm_ticker, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df_ibm_ticker) - window - 1):\n",
    "        features = df_ibm_ticker.iloc[i:(i + window), feature_col_number]\n",
    "        target = df_ibm_ticker.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating function to pull ticker names\n",
    "def training_model(Current_ticker):\n",
    "    df_ibm_ticker = api.get_barset(\n",
    "       tickers,\n",
    "       timeframe,\n",
    "       start=start_date,\n",
    "       end=end_date,\n",
    "       limit=1000\n",
    "    ).df\n",
    "    # Display sample data\n",
    "    df_ibm_ticker.head()\n",
    "    \n",
    "    #\n",
    "    data = np.array(df_ibm_ticker)\n",
    "\n",
    "    # train test split, we can take last 100 data points as test set\n",
    "    train , test = data[0:-100], data[-100:]\n",
    "    \n",
    "   \n",
    "        # Predict Closing Prices using a 10 day window of previous closing prices\n",
    "    # Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "    window_size = 10\n",
    "\n",
    "    # Column index 0 is the 'IBM ' column\n",
    "    # Column index 1 is the `Close` column\n",
    "    feature_column = 1\n",
    "    target_column = 1\n",
    "    X, y = window_data(df_ibm_ticker, window_size, feature_column, target_column)\n",
    "    \n",
    "\n",
    "        # Use 70% of the data for training and the remaineder for testing\n",
    "    data_train = int(.7 * len(X))\n",
    "    X_train = X[:data_train - 1]\n",
    "    X_test = X[data_train:]\n",
    "    y_train = y[:data_train - 1]\n",
    "    y_test = y[data_train:]\n",
    "    \n",
    "        # Use the MinMaxScaler to scale data between 0 and 1.\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    x_train_scaler = MinMaxScaler()\n",
    "    x_test_scaler = MinMaxScaler()\n",
    "    y_train_scaler = MinMaxScaler()\n",
    "    y_test_scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler for the training Data\n",
    "    x_train_scaler.fit(X_train)\n",
    "    y_train_scaler.fit(y_train)\n",
    "\n",
    "    # Scale the training data\n",
    "    X_train = x_train_scaler.transform(X_train)\n",
    "    y_train = y_train_scaler.transform(y_train)\n",
    "\n",
    "    # Fit the scaler for the testing Data\n",
    "    x_test_scaler.fit(X_test)\n",
    "    y_test_scaler.fit(y_test)\n",
    "\n",
    "    # Scale the y_test data\n",
    "    X_test = x_test_scaler.transform(X_test)\n",
    "    y_test = y_test_scaler.transform(y_test)\n",
    "\n",
    "        # Reshape the features for the model\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build the LSTM model. \n",
    "        # Note: The input shape is the number of time steps and the number of indicators\n",
    "    # Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        units=30, return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=30, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=30))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "        # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Summarize the model\n",
    "    #model.summary()\n",
    "    \n",
    "        # Train the model\n",
    "    # Use at least 10 epochs\n",
    "    model.fit(X_train, y_train, epochs=5, shuffle=False, batch_size=1,\n",
    "        verbose=1)\n",
    "    \n",
    "        # Evaluate the model\n",
    "    model.evaluate(X_test, y_test)\n",
    "    \n",
    "            # Make some predictions\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "        # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = y_test_scaler.inverse_transform(predicted)\n",
    "    real_prices = y_test_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "        # Create a DataFrame of Real and Predicted values\n",
    "    stocks = pd.DataFrame({\n",
    "        \"Real\": real_prices.ravel(),\n",
    "        \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = df_ibm_ticker.index[-len(real_prices): ]) \n",
    "    stocks.head()\n",
    "    \n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "416/416 [==============================] - 48s 42ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "416/416 [==============================] - 22s 52ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "416/416 [==============================] - 20s 49ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "416/416 [==============================] - 17s 42ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "416/416 [==============================] - 17s 41ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-14 04:00:00+00:00</th>\n",
       "      <td>39.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15 04:00:00+00:00</th>\n",
       "      <td>39.0100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16 04:00:00+00:00</th>\n",
       "      <td>41.9800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-17 04:00:00+00:00</th>\n",
       "      <td>38.6296</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-18 04:00:00+00:00</th>\n",
       "      <td>38.2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25 04:00:00+00:00</th>\n",
       "      <td>30.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26 04:00:00+00:00</th>\n",
       "      <td>36.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-27 04:00:00+00:00</th>\n",
       "      <td>34.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-28 04:00:00+00:00</th>\n",
       "      <td>32.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 04:00:00+00:00</th>\n",
       "      <td>32.0500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Real  Predicted\n",
       "time                                         \n",
       "2020-09-14 04:00:00+00:00  39.5000        NaN\n",
       "2020-09-15 04:00:00+00:00  39.0100        NaN\n",
       "2020-09-16 04:00:00+00:00  41.9800        NaN\n",
       "2020-09-17 04:00:00+00:00  38.6296        NaN\n",
       "2020-09-18 04:00:00+00:00  38.2000        NaN\n",
       "...                            ...        ...\n",
       "2021-05-25 04:00:00+00:00  30.5000        NaN\n",
       "2021-05-26 04:00:00+00:00  36.0000        NaN\n",
       "2021-05-27 04:00:00+00:00  34.5000        NaN\n",
       "2021-05-28 04:00:00+00:00  32.0000        NaN\n",
       "2021-06-01 04:00:00+00:00  32.0500        NaN\n",
       "\n",
       "[180 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model([\"IBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small cap\n",
      "Epoch 1/5\n",
      "416/416 [==============================] - 50s 37ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "416/416 [==============================] - 14s 33ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "416/416 [==============================] - 12s 29ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "416/416 [==============================] - 16s 40ms/step - loss: nan0s - los\n",
      "Epoch 5/5\n",
      "416/416 [==============================] - 15s 36ms/step - loss: nan\n",
      "                              Real  Predicted\n",
      "time                                         \n",
      "2020-09-14 04:00:00+00:00  39.5000        NaN\n",
      "2020-09-15 04:00:00+00:00  39.0100        NaN\n",
      "2020-09-16 04:00:00+00:00  41.9800        NaN\n",
      "2020-09-17 04:00:00+00:00  38.6296        NaN\n",
      "2020-09-18 04:00:00+00:00  38.2000        NaN\n",
      "...                            ...        ...\n",
      "2021-05-25 04:00:00+00:00  30.5000        NaN\n",
      "2021-05-26 04:00:00+00:00  36.0000        NaN\n",
      "2021-05-27 04:00:00+00:00  34.5000        NaN\n",
      "2021-05-28 04:00:00+00:00  32.0000        NaN\n",
      "2021-06-01 04:00:00+00:00  32.0500        NaN\n",
      "\n",
      "[180 rows x 2 columns]\n",
      "Mid cap\n",
      "Epoch 1/5\n",
      "416/416 [==============================] - 46s 36ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "416/416 [==============================] - 15s 36ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "416/416 [==============================] - 15s 37ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "416/416 [==============================] - 14s 34ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "416/416 [==============================] - 12s 29ms/step - loss: nan\n",
      "                              Real  Predicted\n",
      "time                                         \n",
      "2020-09-14 04:00:00+00:00  39.5000        NaN\n",
      "2020-09-15 04:00:00+00:00  39.0100        NaN\n",
      "2020-09-16 04:00:00+00:00  41.9800        NaN\n",
      "2020-09-17 04:00:00+00:00  38.6296        NaN\n",
      "2020-09-18 04:00:00+00:00  38.2000        NaN\n",
      "...                            ...        ...\n",
      "2021-05-25 04:00:00+00:00  30.5000        NaN\n",
      "2021-05-26 04:00:00+00:00  36.0000        NaN\n",
      "2021-05-27 04:00:00+00:00  34.5000        NaN\n",
      "2021-05-28 04:00:00+00:00  32.0000        NaN\n",
      "2021-06-01 04:00:00+00:00  32.0500        NaN\n",
      "\n",
      "[180 rows x 2 columns]\n",
      "Large cap\n",
      "Epoch 1/5\n",
      "416/416 [==============================] - 58s 47ms/step - loss: nan\n",
      "Epoch 2/5\n",
      "416/416 [==============================] - 18s 44ms/step - loss: nan\n",
      "Epoch 3/5\n",
      "416/416 [==============================] - 19s 47ms/step - loss: nan\n",
      "Epoch 4/5\n",
      "416/416 [==============================] - 18s 43ms/step - loss: nan\n",
      "Epoch 5/5\n",
      "416/416 [==============================] - 16s 38ms/step - loss: nan\n",
      "                              Real  Predicted\n",
      "time                                         \n",
      "2020-09-14 04:00:00+00:00  39.5000        NaN\n",
      "2020-09-15 04:00:00+00:00  39.0100        NaN\n",
      "2020-09-16 04:00:00+00:00  41.9800        NaN\n",
      "2020-09-17 04:00:00+00:00  38.6296        NaN\n",
      "2020-09-18 04:00:00+00:00  38.2000        NaN\n",
      "...                            ...        ...\n",
      "2021-05-25 04:00:00+00:00  30.5000        NaN\n",
      "2021-05-26 04:00:00+00:00  36.0000        NaN\n",
      "2021-05-27 04:00:00+00:00  34.5000        NaN\n",
      "2021-05-28 04:00:00+00:00  32.0000        NaN\n",
      "2021-06-01 04:00:00+00:00  32.0500        NaN\n",
      "\n",
      "[180 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "for(name,l) in groups.items():\n",
    "    print (name)\n",
    "    print (training_model(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
